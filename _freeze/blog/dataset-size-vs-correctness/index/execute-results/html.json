{
  "hash": "7a3f2419f723e6bc35f6ab42d768ed65",
  "result": {
    "markdown": "---\ntitle: \"Dataset Size vs. Label Correctness: What is more important for training a model?\"\nauthor: \"Paul Simmering\"\ndate: \"2023-10-28\"\ncategories: [\"Machine Learning\", \"Python\"]\nimage: \"scale.png\"\nformat:\n    html:\n        mermaid: \n          theme: neutral\n---\n\n![Illustration created with DALLÂ·E 3](scale-wide.png)\n\nSupervised models are trained on labeled data. The more data, the better the model. But what if the labels are wrong? How much does the quality of the labels matter compared to the quantity of the data?\n\nIn this article, I'll explore this question by training the [DistilBERT](https://huggingface.co/docs/transformers/model_doc/distilbert) transformer model on the IMDB movie review sentiment [dataset](https://huggingface.co/datasets/imdb) with different amounts of data and different amounts of label noise. The results show that the model is rather robust to label noise, meaning that more data can make up for a certain amount of label noise. That doesn't mean that label noise is not a problem, but that prioritizing data collection over label correction can be a viable strategy.\n\nHere's an overview of the steps I'll take:\n\n\n```{mermaid}\nflowchart LR\n  A([Movie reviews]) --> B[Training set]\n    A --> C[Test set]\n    subgraph \"Experiment\"\n      B --> D[Subsample]\n      D --> E[Add label noise]\n      E --> F[Finetune]\n      H[Pretrained Model] --> F\n      F --> G[Finetuned Model]\n      G --> I[Evaluate]\n    end\n    C --> I\n    I --> J[Compare Accuracies]\n\n```\n\n\n1. Split the movie reviews into a training and test set.\n2. Run experiments. For each combination of dataset size and label noise:\n    1. Subsample the training set to the desired size.\n    2. Flip a certain percentage of labels to introduce label noise.\n    3. Fine-tune a pretrained transformer model on the training set.\n    4. Evaluate the fine-tuned model on the test set.\n3. Compare the accuracy achieved by the model for each combination of dataset size and label noise.\n\nThe model training section loosely follows the [HuggingFace tutorial](https://huggingface.co/course/chapter1/3?fw=pt) on training a sentiment classifier.\n\n::: {.callout-note}\nTo run the large number of experiments, I used [Modal](https://modal.com), a serverless compute platform. The code snippets in this article are simplified and use subsampling to be able to run on a laptop. The full experiment code is available on [GitHub](https://github.com/psimm/website/blob/master/blog/dataset-size-vs-correctness/train.py).\n:::\n\n## Quick overview of the IMDB Movie Review Dataset\n\nIt's a dataset of 50,000 movie reviews from [IMDB](https://www.imdb.com), labeled as positive (1) or negative (0). The dataset is split into 25,000 training and 25,000 test reviews. Let's load it from [HuggingFace](https://huggingface.co/datasets/imdb) and have a look:\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom datasets import load_dataset\n\nimdb = load_dataset(\"imdb\")\nimdb[\"train\"].to_pandas().head(3)\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>If only to avoid making this type of film in t...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nAnd the balanced label distribution in the training set:\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimdb[\"train\"].to_pandas()[\"label\"].value_counts()\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```\nlabel\n0    12500\n1    12500\nName: count, dtype: int64\n```\n:::\n:::\n\n\n## Setup: Dataset size and label noise\n\n### Experiment grid\n\nThe next step is to define a grid of combinations of dataset size and label noise. As the actual accuracy achieved isn't the main point of this experiment, and many models have to be trained, I'll not use the full dataset. The dataset size will range from 1000 to 5,000 examples and the label noise (the percentage of labels that are flipped) will range from 0 to 25%.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nfrom itertools import product\n\ndataset_sizes = np.arange(1000, 5001, 1000)\nnoise_levels = np.arange(0, 0.25, 0.025)\n\ncombinations = list(product(dataset_sizes, noise_levels))\nprint(f\"Number of combinations: {len(combinations)}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of combinations: 50\n```\n:::\n:::\n\n\n### Dataset subsampling\n\nOn each run, I'll subsample the training set to the desired size. To keep the balance of the labels intact, I'll subsample the positive and negative examples separately and then concatenate them. To reduce time spent on evaluating the model, I'll also subsample the test set to 2,000 examples.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom datasets import concatenate_datasets, Dataset\n\n\ndef subsample_hf_dataset(dataset: Dataset, max_size: int):\n    # Shuffle dataset\n    dataset = dataset.shuffle(seed=42)\n\n    # Separate datasets with labels 0 and 1\n    dataset_label_0 = dataset.filter(lambda example: example[\"label\"] == 0)\n    dataset_label_1 = dataset.filter(lambda example: example[\"label\"] == 1)\n\n    # Subsample datasets\n    subsampled_dataset_label_0 = dataset_label_0.select(range(max_size // 2))\n    subsampled_dataset_label_1 = dataset_label_1.select(range(max_size // 2))\n\n    # Concatenate subsampled datasets\n    return concatenate_datasets(\n        [subsampled_dataset_label_0, subsampled_dataset_label_1]\n    )\n\n\nimdb_train = subsample_hf_dataset(imdb[\"train\"], max(dataset_sizes))\nimdb_test = subsample_hf_dataset(imdb[\"train\"], 2000)\n```\n:::\n\n\n### Preprocessing\n\nThe transformer model expects the input to be tokenized and encoded. I'll use the [DistilBERT tokenizer](https://huggingface.co/distilbert-base-uncased) for this.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True)\n\n\ntokenized_train = imdb_train.map(preprocess_function, batched=True)\ntokenized_test = imdb_test.map(preprocess_function, batched=True)\n```\n:::\n\n\nNext, convert the datasets to PyTorch tensors and pad the sequences to the same length.\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfrom transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n```\n:::\n\n\n### Make some noise\n\nTo introduce label noise, I'll randomly flip the labels of a certain percentage of the training set. Again, I'll leave the balance of the labels intact.\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nfrom random import sample, seed\n\n\ndef flip_labels(dataset: Dataset, noise_level: float):\n    # make the operation deterministic\n    seed(42)\n\n    # get number of labels to flip\n    n = int(len(dataset) * noise_level)\n    n_by_class = n // 2\n\n    # get indices of labels to flip\n    neg_indices = [i for i, example in enumerate(dataset) if example[\"label\"] == 0]\n    pos_indices = [i for i, example in enumerate(dataset) if example[\"label\"] == 1]\n\n    selected_neg_indices = sample(neg_indices, n_by_class)\n    selected_pos_indices = sample(pos_indices, n_by_class)\n\n    # combine indices\n    indices_to_flip = selected_neg_indices + selected_pos_indices\n\n    # function to apply to flip the labels\n    def flip_labels_function(example, idx: int):\n        # flip the label if index is in the selected indices\n        # this is not the fastest way to do this, but it's easy to understand\n        if idx in indices_to_flip:\n            example[\"label\"] = 1 if example[\"label\"] == 0 else 0\n        return example\n\n    # apply function to flip the labels\n    return dataset.map(flip_labels_function, with_indices=True)\n\n```\n:::\n\n\nThis function will be used later in a loop.\n\n## Training the model\n\nFirst, we download a pre-trained transformer model that has not been fine-tuned for sentiment classification yet. One of the most commonly used models is [DistilBERT](https://huggingface.co/distilbert-base-uncased), a smaller, more efficient version of [BERT](https://huggingface.co/bert-base-uncased).\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nfrom transformers import AutoModelForSequenceClassification\nimport torch\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=2\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n```\n:::\n:::\n\n\nNext, let's set the training arguments.\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nfrom transformers import TrainingArguments\n\ntrain_args = TrainingArguments(\n    learning_rate=2e-5,  # how fast the model learns\n    per_device_train_batch_size=16,  # how many training examples are processed at once\n    per_device_eval_batch_size=16,  # how many test examples are processed at once\n    num_train_epochs=2,  # how many times the model sees the training data\n    weight_decay=0.01,  # how much the model is penalized for being complex\n    output_dir=\"./results\",\n)\n```\n:::\n\n\nAfter training, we'll evaluate the model on the test set. The evaluation metric is accuracy, the percentage of correctly classified examples.\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nfrom datasets import load_metric\n\n\ndef compute_metrics(eval_pred):\n    load_accuracy = load_metric(\"accuracy\")\n\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\n        \"accuracy\"\n    ]\n    return {\"accuracy\": accuracy}\n\n```\n:::\n\n\nFinally, we have all the pieces to run the experiment. Let's put them together in an experiment function.\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nfrom transformers import Trainer\nimport time\n\n\ndef train_and_evaluate(dataset_size: int, noise_level: float) -> dict:\n    train_sub = subsample_hf_dataset(tokenized_train, dataset_size)\n    train_sub = flip_labels(train_sub, noise_level)\n\n    trainer = Trainer(\n        model=model,\n        args=train_args,\n        train_dataset=train_sub,\n        eval_dataset=tokenized_test,\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics,\n    )\n\n    train_start = time.time()\n    trainer.train()\n    train_time = time.time() - train_start\n\n    evaluation = trainer.evaluate()\n\n    evaluation.update(\n        {\n            \"dataset_size\": dataset_size,\n            \"noise_level\": noise_level,\n            \"train_time\": train_time,\n        }\n    )\n\n    return evaluation\n\n```\n:::\n\n\nThis function runs a single experiment:\n\n\n```{mermaid}\nflowchart LR\n  A([Training set]) --> B[Subsample]\n    B --> C[Add label noise]\n    C --> D[Finetune]\n    E[Pretrained Model] --> D\n    D --> F[Finetuned Model]\n    F --> G[Evaluate]\n\n```\n\n\nFinally, we can run all experiments and save the results to a CSV file.\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nimport pandas as pd\n\nresults = pd.DataFrame()\n\nfor dataset_size, noise_level in combinations:\n    evaluation = train_and_evaluate(dataset_size, noise_level)\n    results = pd.concat([results, pd.DataFrame([evaluation])])\n\n    with open(results_path, \"w\") as f:\n        pd.DataFrame(results).to_csv(f, index=False)\n```\n:::\n\n\n::: {.callout-note}\nNote that this loop runs slowly unless you have a GPU available. Rather than actually running the experiment in a single loop on my laptop, I've combined the code in a [Python script](https://github.com/psimm/website/blog/correctness-vs-size/train.py) that parallelizes the experiment on [Modal](https://modal.com) using up to 20 A10G GPUs in parallel. In addition, that script features a wider range of dataset sizes and label noise levels and doesn't subsample the test set. All further code snippets in this article are based on the results from that script.\n:::\n\n![Training in Modal](modal.png)\n\nThe total cost was $30. This fit into the free tier of Modal.\n\n## Results\n\nLet's plot the accuracy achieved by the model for each combination of dataset size and label noise.\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nimport plotly.graph_objects as go\nimport pandas as pd\n\ndf = pd.read_csv(\"./results_from_modal.csv\")\n\n# Pivot the dataframe\npivot_df = df.pivot(index=\"train_size\", columns=\"noise_level\", values=\"eval_accuracy\")\n\n# Create text for hover tooltip\nhover_text = [\n    [\n        f\"Training examples: {y}<br>Noise level: {x}<br>Accuracy: {z}\"\n        for x, z in zip(pivot_df.columns, row)\n    ]\n    for y, row in zip(pivot_df.index, pivot_df.values)\n]\n\nfig = go.Figure(\n    data=go.Heatmap(\n        z=pivot_df.values,\n        x=pivot_df.columns.values,\n        y=pivot_df.index.values,\n        hovertext=hover_text,\n        hoverinfo=\"text\",\n        colorscale=\"Viridis\",\n        colorbar=dict(title=\"Accuracy\"),\n    )\n)\n\nfig.update_layout(\n    xaxis_title=\"Noise Level\",\n    yaxis_title=\"Training Examples\",\n)\n\nfig.show()\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>                            <div id=\"5d1fc1e5-3f93-4894-bc1a-fdf7eee3154a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5d1fc1e5-3f93-4894-bc1a-fdf7eee3154a\")) {                    Plotly.newPlot(                        \"5d1fc1e5-3f93-4894-bc1a-fdf7eee3154a\",                        [{\"colorbar\":{\"title\":{\"text\":\"Accuracy\"}},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"hoverinfo\":\"text\",\"hovertext\":[[\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.8746\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.8741\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.8745\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.8816\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.8721\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.868\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.872\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.8762\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8722\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8646\",\"Training examples: 1000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8494\"],[\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9005\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.8972\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.8937\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.8889\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.8879\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.8879\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.8857\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.8816\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8806\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8806\",\"Training examples: 2000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8774\"],[\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9029\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9017\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9001\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.8922\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.8904\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.8958\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.8967\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.892\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8875\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8838\",\"Training examples: 3000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8799\"],[\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9094\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.906\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9018\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9007\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.899\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.8963\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.8934\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.8907\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.889\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8852\",\"Training examples: 4000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8855\"],[\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9121\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9091\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.907\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9066\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9033\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.8979\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.8989\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.8952\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8909\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8882\",\"Training examples: 5000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8889\"],[\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9141\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9117\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9098\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9078\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9055\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9029\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.8985\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.8985\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8962\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.89\",\"Training examples: 6000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8822\"],[\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9161\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9149\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.913\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9115\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.906\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9069\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.8996\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.897\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8968\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8884\",\"Training examples: 7000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8879\"],[\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9166\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9174\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9129\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9125\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.91\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.91\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.9047\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.9056\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8988\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8927\",\"Training examples: 8000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.89\"],[\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9208\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9193\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9174\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9124\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9093\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9061\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.906\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.904\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.9006\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8943\",\"Training examples: 9000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8946\"],[\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9229\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9196\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9187\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.915\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9117\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9089\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.9069\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.9068\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.9047\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8995\",\"Training examples: 10000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8985\"],[\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9206\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9207\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.921\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9147\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9119\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9094\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.9085\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.8989\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8992\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8933\",\"Training examples: 11000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8924\"],[\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9231\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.921\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9192\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9157\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9125\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9116\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.908\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.908\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.9044\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.9024\",\"Training examples: 12000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8962\"],[\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.924\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9223\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9217\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9166\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9139\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9093\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.9054\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.9011\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.8969\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.8969\",\"Training examples: 13000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8913\"],[\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9249\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9229\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9177\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9167\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9157\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9099\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.9087\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.9041\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.9054\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.9023\",\"Training examples: 14000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8971\"],[\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.0\\u003cbr\\u003eAccuracy: 0.9257\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.025\\u003cbr\\u003eAccuracy: 0.9239\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.05\\u003cbr\\u003eAccuracy: 0.9218\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.075\\u003cbr\\u003eAccuracy: 0.9183\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.1\\u003cbr\\u003eAccuracy: 0.9186\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.125\\u003cbr\\u003eAccuracy: 0.9136\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.15\\u003cbr\\u003eAccuracy: 0.9145\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.175\\u003cbr\\u003eAccuracy: 0.9092\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.2\\u003cbr\\u003eAccuracy: 0.9086\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.225\\u003cbr\\u003eAccuracy: 0.9029\",\"Training examples: 15000\\u003cbr\\u003eNoise level: 0.25\\u003cbr\\u003eAccuracy: 0.8986\"]],\"x\":[0.0,0.025,0.05,0.075,0.1,0.125,0.15,0.175,0.2,0.225,0.25],\"y\":[1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,14000,15000],\"z\":[[0.8746,0.8741,0.8745,0.8816,0.8721,0.868,0.872,0.8762,0.8722,0.8646,0.8494],[0.9005,0.8972,0.8937,0.8889,0.8879,0.8879,0.8857,0.8816,0.8806,0.8806,0.8774],[0.9029,0.9017,0.9001,0.8922,0.8904,0.8958,0.8967,0.892,0.8875,0.8838,0.8799],[0.9094,0.906,0.9018,0.9007,0.899,0.8963,0.8934,0.8907,0.889,0.8852,0.8855],[0.9121,0.9091,0.907,0.9066,0.9033,0.8979,0.8989,0.8952,0.8909,0.8882,0.8889],[0.9141,0.9117,0.9098,0.9078,0.9055,0.9029,0.8985,0.8985,0.8962,0.89,0.8822],[0.9161,0.9149,0.913,0.9115,0.906,0.9069,0.8996,0.897,0.8968,0.8884,0.8879],[0.9166,0.9174,0.9129,0.9125,0.91,0.91,0.9047,0.9056,0.8988,0.8927,0.89],[0.9208,0.9193,0.9174,0.9124,0.9093,0.9061,0.906,0.904,0.9006,0.8943,0.8946],[0.9229,0.9196,0.9187,0.915,0.9117,0.9089,0.9069,0.9068,0.9047,0.8995,0.8985],[0.9206,0.9207,0.921,0.9147,0.9119,0.9094,0.9085,0.8989,0.8992,0.8933,0.8924],[0.9231,0.921,0.9192,0.9157,0.9125,0.9116,0.908,0.908,0.9044,0.9024,0.8962],[0.924,0.9223,0.9217,0.9166,0.9139,0.9093,0.9054,0.9011,0.8969,0.8969,0.8913],[0.9249,0.9229,0.9177,0.9167,0.9157,0.9099,0.9087,0.9041,0.9054,0.9023,0.8971],[0.9257,0.9239,0.9218,0.9183,0.9186,0.9136,0.9145,0.9092,0.9086,0.9029,0.8986]],\"type\":\"heatmap\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"Noise Level\"}},\"yaxis\":{\"title\":{\"text\":\"Training Examples\"}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('5d1fc1e5-3f93-4894-bc1a-fdf7eee3154a');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>\n```\n:::\n:::\n\n\nThe heatmap is interactive, so you can hover over the cells to see the exact accuracy achieved for each combination of dataset size and label noise.\n\nWhat can we learn from this plot?\n\n- The accuracy increases with the number of training examples, as expected.\n- Accuracy decreases with noise level, as expected.\n- Dataset size can compensate for a certain amount of label noise.\n- Even with a noise level of 0.25, the model can still achieve an accuracy of 0.89 with 15,000 training examples. This demonstrates a robustness to label noise.\n- The task is rather easy. Even with just 1,000 examples and a noise level of 0.25, the model achieves an accuracy of 0.85.\n\nHow can number of examples and noise level be traded off? Let's find out with a regression model.\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nimport statsmodels.formula.api as smf\n\n# Transform train_size to 1000s\ndf[\"train_size_1k\"] = df[\"train_size\"] / 1000\n\n# Transform noise and accuracy to percentages\ndf[\"noise_level_pct\"] = df[\"noise_level\"] * 100\ndf[\"eval_accuracy_pct\"] = df[\"eval_accuracy\"] * 100\n\n# Fit a model and extract coefficients\nmodel = smf.ols(\"eval_accuracy_pct ~ train_size_1k + noise_level_pct\", data=df).fit()\n\npd.DataFrame(\n    {\n        \"Coefficient\": model.params,\n        \"P-Value\": model.pvalues,\n        \"Conf. Int. Lower\": model.conf_int()[0],\n        \"Conf. Int. Upper\": model.conf_int()[1],\n    }\n)\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Coefficient</th>\n      <th>P-Value</th>\n      <th>Conf. Int. Lower</th>\n      <th>Conf. Int. Upper</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Intercept</th>\n      <td>89.683593</td>\n      <td>2.109041e-288</td>\n      <td>89.446360</td>\n      <td>89.920826</td>\n    </tr>\n    <tr>\n      <th>train_size_1k</th>\n      <td>0.226422</td>\n      <td>3.696455e-49</td>\n      <td>0.205562</td>\n      <td>0.247282</td>\n    </tr>\n    <tr>\n      <th>noise_level_pct</th>\n      <td>-0.103253</td>\n      <td>3.439962e-40</td>\n      <td>-0.114654</td>\n      <td>-0.091853</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe regression model provides coefficients that estimate the importance of each variable. All are significant at the 0.01 level.\n\nIn this simplified model, each percentage point of noise is worth as much as 500 examples. Let's imagine a scenario: You have 10,000 labels with a noise level of 10%. You could either correct 100 labels or collect 500 more labels to get the same approximate accuracy improvement. The hard part is figuring out which labels are incorrect. If you can't do that without checking every label manually, it may be more economical to collect more data.\n\nNote that the regression's logic is failing at the extremes. For example a model with 0 examples wouldn't be able to achieve a baseline accuracy of 89.7% as indicated by the intercept.\n\n## Conclusion\n\nIn this article, I've trained a sentiment analysis model on different amounts of data with different amounts of label noise. The results show that the model is rather robust to label noise, meaning that more data can make up for a certain amount of label noise. That doesn't mean that label noise is not a problem, but that prioritizing data collection over label correction can be a viable strategy.\n\nOne drawback of this experiment is that it only considers a single model and a single dataset. It would be interesting to see if the results generalize to other models and datasets.\n\nFurther reading:\nZhu, Dawei, et al. \"Is BERT robust to label noise? A study on learning with noisy labels in text classification.\" [arXiv preprint arXiv:2204.09371](https://arxiv.org/pdf/2204.09371.pdf)(2022).\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script type=\"text/javascript\">\nwindow.PlotlyConfig = {MathJaxConfig: 'local'};\nif (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\nif (typeof require !== 'undefined') {\nrequire.undef(\"plotly\");\nrequirejs.config({\n    paths: {\n        'plotly': ['https://cdn.plot.ly/plotly-2.26.0.min']\n    }\n});\nrequire(['plotly'], function(Plotly) {\n    window._Plotly = Plotly;\n});\n}\n</script>\n\n"
      ]
    }
  }
}